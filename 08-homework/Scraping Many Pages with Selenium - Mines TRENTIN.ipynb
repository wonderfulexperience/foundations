{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping many pages + Using Selenium\n",
    "\n",
    "## The pages we'll be looking at\n",
    "\n",
    "If I wanted to read specific information about a specfic mine, it takes a few steps. **Do these steps with your browser before you try any programming.**\n",
    "\n",
    "1. Visit the [Mine Data Retrieval System](https://arlweb.msha.gov/drs/drshome.htm)\n",
    "2. Scroll down to **Mine Identification Number (ID) Search**\n",
    "3. Type in a mine ID number, such as `3503598`, click **Search**\n",
    "4. I'm on a page! It lists the MINE NAME and MINE OWNER.\n",
    "\n",
    "After searching for and finding a mine, I can use this page to **find reports about this mine**. Some of the reports are on accidents, violations, inspections, health samples and more. To get those reports:\n",
    "\n",
    "1. Search for a mine (if you haven't already)\n",
    "2. Scroll down and change **Beginning Date** to `1/1/1995` (violation reports begin in 1995, accidents begin in 1983)\n",
    "3. Select the report type of `Violations`\n",
    "4. Click **Get Report**\n",
    "5. I'm on a page! It lists ALL OF THE MINE'S VIOLATIONS.\n",
    "\n",
    "By changing the report type you're searching for you can find all sorts of different data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Researching mine information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation \n",
    "\n",
    "### When you search for information on a specific mine, what URL should Selenium visit first?\n",
    "\n",
    "- *TIP: the answer is NOT `https://arlweb.msha.gov/drs/ASP/BasicMineInfonew.asp`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='https://arlweb.msha.gov/drs/drshome.htm'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can you identify the text field we're going to type the Mine ID into?\n",
    "\n",
    "Selenium can find elements by:\n",
    "\n",
    "- name\n",
    "- Class\n",
    "- ID\n",
    "- CSS selector (**ASK ME WHAT THIS IS** if you don't know)\n",
    "- XPath (**ASK ME WHAT THIS IS** because you definitely don't know)\n",
    "- Link text\n",
    "- Partial link text\n",
    "\n",
    "So in other words, what's unique about this element?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mineID_Field = driver.find_element_by_name(\"MineId\")\n",
    "#searching by XPath was not getting the right input field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How can you identify the search button we're going to click, or the form we're going to submit?\n",
    "\n",
    "Selenium can submit forms by either\n",
    "\n",
    "- Selecting the form and using `.submit()`, or\n",
    "- Selecting the button and using `.click()`\n",
    "\n",
    "You only need to be able to get **one, not both.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xPath_SearchButton = '//*[@id=\"content\"]/table[3]/tbody/tr[3]/td[2]/input'\n",
    "searchButton = driver.find_element_by_xpath(xPath_SearchButton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Selenium to search using the mine ID `3901432`. Get me the operator's name by scraping.\n",
    "\n",
    "- *TIP: You can find elements/text using Selenium, or use BeautifulSoup with `doc = BeautifulSoup(driver.page_source)`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mineID_Field.click()\n",
    "mineID_Field.send_keys(\"3901432\")\n",
    "searchButton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Krueger Brothers Gravel & Dirt\n"
     ]
    }
   ],
   "source": [
    "doc = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "for line in doc.find_all():\n",
    "    if line.text == \"Operator:\":\n",
    "        print(line.find_next(\"b\").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using .apply to find data about SEVERAL mines\n",
    "\n",
    "The file `mines-subset.csv` has a list of mine IDs. We're going to scrape the operator's name for each of those mines.\n",
    "\n",
    "### Open up `mines-subset.csv` and save it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('mines-subset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open up `mines-subset.csv` in a text editor, then look at your dataframe. Is something different about them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#one starts with a 0, IDs have to be changed to a string\n",
    "df = pd.read_csv('mines-subset.csv', converters={'id': str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the operator's name for each of those mines and print it\n",
    "\n",
    "- *TIP: use .apply and a function*\n",
    "- *TIP: If you need help with .apply, look at the \"Using apply in pandas\" notebook *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dirt Works\n",
      "Holley Dirt Company, Inc\n",
      "M.R. Dirt Inc.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_page(row):\n",
    "    driver.get(url)\n",
    "    mineID_Field = driver.find_element_by_name(\"MineId\")\n",
    "    xPath_SearchButton = '//*[@id=\"content\"]/table[3]/tbody/tr[3]/td[2]/input'\n",
    "    searchButton = driver.find_element_by_xpath(xPath_SearchButton)\n",
    "    mineID_Field.click()\n",
    "    mineID_Field.send_keys(row['id'])\n",
    "    searchButton.click()\n",
    "    doc = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    mine_name = \"\"\n",
    "    for line in doc.find_all():\n",
    "        if line.text == \"Operator:\":\n",
    "            mine_name = line.find_next(\"b\").text\n",
    "            print(mine_name)\n",
    "\n",
    "df.apply(scrape_page, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the operator's name and save it into a new column\n",
    "\n",
    "- *TIP: Use .apply and a function*\n",
    "- *TIP: Remember to use `return`*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>mine_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4104757</td>\n",
       "      <td>Dirt Works</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0801306</td>\n",
       "      <td>Holley Dirt Company, Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3609931</td>\n",
       "      <td>M.R. Dirt Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                 mine_name\n",
       "0  4104757                Dirt Works\n",
       "1  0801306  Holley Dirt Company, Inc\n",
       "2  3609931            M.R. Dirt Inc."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_page(row):\n",
    "    driver.get(url)\n",
    "    mineID_Field = driver.find_element_by_name(\"MineId\")\n",
    "    xPath_SearchButton = '//*[@id=\"content\"]/table[3]/tbody/tr[3]/td[2]/input'\n",
    "    searchButton = driver.find_element_by_xpath(xPath_SearchButton)\n",
    "    mineID_Field.click()\n",
    "    mineID_Field.send_keys(row['id'])\n",
    "    searchButton.click()\n",
    "    doc = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    mine_name = \"\"\n",
    "    for line in doc.find_all():\n",
    "        if line.text == \"Operator:\":\n",
    "            mine_name = line.find_next(\"b\").text\n",
    "    return mine_name\n",
    "\n",
    "df['mine_name'] = df.apply(scrape_page, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Researching mine violations\n",
    "\n",
    "Read the very top again to remember how to find mine violations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you search for a mine's violations, what URL is Selenium going to start on?\n",
    "\n",
    "- *TIP: `requests` can send form data to load in the middle of a bunch of steps, but Selenium has to start at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# same URL as before to search for a specific mine first\n",
    "url='https://arlweb.msha.gov/drs/drshome.htm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you're searching for violations from the Mine Information page, how are you going to identify the \"Beginning Date\" field?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# beginningDate_field = driver.find_element_by_name(\"BDate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When you're searching for violations from the Mine Information page, how are you going to identify the \"Violations\" button?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# violations_button = driver.find_element_by_xpath(\"//input[(@type='radio') and (@value = 'Violations*')]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### When you're searching for violations from the Mine Information page, how are you going to identify the form or the button to click to get a list of the violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# submit_button = driver.find_element_by_xpath(\"//input[(@alt='Submit Request')]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the mine ID `3901432`, scrape all of their violations since 1/1/1995\n",
    "\n",
    "**Save this into a CSV called `3901432-violations.csv`.** This CSV must include the following fields:\n",
    "\n",
    "- Citation number\n",
    "- Case number\n",
    "- Standard violated\n",
    "- Link to standard\n",
    "- Proposed penalty\n",
    "- Amount paid to date\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- *TIP: It's probably worth it to print them all first, then save them to a CSV once you know it's all working.*\n",
    "- *TIP: You'll use the parent pattern - get the ROWS first (tr), then loop through and get the TABLE CELLS (td)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "this_MineID = \"3901432\"\n",
    "driver.get(url)\n",
    "mineID_Field = driver.find_element_by_name(\"MineId\")\n",
    "xPath_SearchButton = '//*[@id=\"content\"]/table[3]/tbody/tr[3]/td[2]/input'\n",
    "searchButton = driver.find_element_by_xpath(xPath_SearchButton)\n",
    "mineID_Field.click()\n",
    "mineID_Field.send_keys(this_MineID)\n",
    "searchButton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beginningDate_field = driver.find_element_by_name(\"BDate\")\n",
    "violations_button = driver.find_element_by_xpath(\"//input[(@type='radio') and (@value = 'Violations*')]\")\n",
    "submit_button = driver.find_element_by_xpath(\"//input[(@alt='Submit Request')]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beginningDate_field.send_keys(\"1/1/1995\")\n",
    "violations_button.click()\n",
    "submit_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "violations_list = []\n",
    "violations = doc.find_all(\"tr\",attrs={'class':'drsviols'})\n",
    "\n",
    "for violation in violations:\n",
    "    data = violation.find_all(\"td\")\n",
    "    if data:\n",
    "        current = {}\n",
    "        current[\"Citation number\"] = data[2].text.strip()\n",
    "        current[\"Case number\"] = data[3].text.strip()\n",
    "        current[\"Standard violated\"] = data[10].find_all('font')[2].text.strip()\n",
    "        current[\"Link to standard\"] = data[10].find('a')['href']\n",
    "        current[\"Proposed penalty\"] = data[11].text.strip()\n",
    "        current[\"Amount paid to date\"] = data[14].text.strip()\n",
    "        violations_list.append(current)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount paid to date</th>\n",
       "      <th>Case number</th>\n",
       "      <th>Citation number</th>\n",
       "      <th>Link to standard</th>\n",
       "      <th>Proposed penalty</th>\n",
       "      <th>Standard violated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100.00</td>\n",
       "      <td>000361866</td>\n",
       "      <td>8750964</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-2014-title30-...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>56.18010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100.00</td>\n",
       "      <td>000260865</td>\n",
       "      <td>6426438</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-2011-title30-...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>56.4101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.00</td>\n",
       "      <td>000260865</td>\n",
       "      <td>6426439</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-2011-title30-...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>56.4201(a)(2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.00</td>\n",
       "      <td>000260865</td>\n",
       "      <td>6588189</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-2011-title30-...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>56.14200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100.00</td>\n",
       "      <td>000238554</td>\n",
       "      <td>6588210</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-2010-title30-...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>50.30(a)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100.00</td>\n",
       "      <td>000188398</td>\n",
       "      <td>6328074</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-2009-title30-...</td>\n",
       "      <td>100.00</td>\n",
       "      <td>56.11003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916124</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.14132(a)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916121</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.18002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916118</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.12028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916116</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>50.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916120</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.15001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916117</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916115</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>41.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916125</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916126</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.14100(d)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916123</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.14132(a)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205502</td>\n",
       "      <td>7916119</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.18010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>55.00</td>\n",
       "      <td>390143205501</td>\n",
       "      <td>7916122</td>\n",
       "      <td>http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...</td>\n",
       "      <td>55.00</td>\n",
       "      <td>56.20008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount paid to date   Case number Citation number  \\\n",
       "0               100.00     000361866         8750964   \n",
       "1               100.00     000260865         6426438   \n",
       "2               100.00     000260865         6426439   \n",
       "3               100.00     000260865         6588189   \n",
       "4               100.00     000238554         6588210   \n",
       "5               100.00     000188398         6328074   \n",
       "6                55.00  390143205501         7916124   \n",
       "7                55.00  390143205501         7916121   \n",
       "8                55.00  390143205501         7916118   \n",
       "9                55.00  390143205501         7916116   \n",
       "10               55.00  390143205501         7916120   \n",
       "11               55.00  390143205501         7916117   \n",
       "12               55.00  390143205501         7916115   \n",
       "13               55.00  390143205501         7916125   \n",
       "14               55.00  390143205501         7916126   \n",
       "15               55.00  390143205501         7916123   \n",
       "16               55.00  390143205502         7916119   \n",
       "17               55.00  390143205501         7916122   \n",
       "\n",
       "                                     Link to standard Proposed penalty  \\\n",
       "0   http://www.gpo.gov/fdsys/pkg/CFR-2014-title30-...           100.00   \n",
       "1   http://www.gpo.gov/fdsys/pkg/CFR-2011-title30-...           100.00   \n",
       "2   http://www.gpo.gov/fdsys/pkg/CFR-2011-title30-...           100.00   \n",
       "3   http://www.gpo.gov/fdsys/pkg/CFR-2011-title30-...           100.00   \n",
       "4   http://www.gpo.gov/fdsys/pkg/CFR-2010-title30-...           100.00   \n",
       "5   http://www.gpo.gov/fdsys/pkg/CFR-2009-title30-...           100.00   \n",
       "6   http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "7   http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "8   http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "9   http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "10  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "11  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "12  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "13  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "14  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "15  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "16  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "17  http://www.gpo.gov/fdsys/pkg/CFR-1998-title30-...            55.00   \n",
       "\n",
       "   Standard violated  \n",
       "0           56.18010  \n",
       "1            56.4101  \n",
       "2      56.4201(a)(2)  \n",
       "3           56.14200  \n",
       "4           50.30(a)  \n",
       "5           56.11003  \n",
       "6        56.14132(a)  \n",
       "7           56.18002  \n",
       "8           56.12028  \n",
       "9              50.30  \n",
       "10          56.15001  \n",
       "11           56.1000  \n",
       "12             41.20  \n",
       "13           56.4200  \n",
       "14       56.14100(d)  \n",
       "15       56.14132(a)  \n",
       "16          56.18010  \n",
       "17          56.20008  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(violations_list)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = this_MineID+\"-violations.csv\"\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using .apply to save mine data for SEVERAL mines\n",
    "\n",
    "The file `mines-subset.csv` has a list of mine IDs. We're going to scrape the operator's name for each of those mines.\n",
    "\n",
    "### Open up `mines-subset.csv` and save it into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4104757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0801306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3609931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id\n",
       "0  4104757\n",
       "1  0801306\n",
       "2  3609931"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new = pd.read_csv('mines-subset.csv', converters={'id': str})\n",
    "df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape the violations for each mine\n",
    "\n",
    "**Save each mine's violations into separate CSV files.** Each CSV file must include the following fields:\n",
    "\n",
    "- Citation number\n",
    "- Case number\n",
    "- Standard violated\n",
    "- Link to standard\n",
    "- Proposed penalty\n",
    "- Amount paid to date\n",
    "\n",
    "Make sure you are saving them into **separate files.** It might be nice to name them after the mine id.\n",
    "\n",
    "- *TIP: Use .apply for this*\n",
    "- *TIP: Print out the ID before you start scraping. That way you can take that ID and search manually to see if there is anything weird about the results.*\n",
    "- *TIP: If you need help with .apply, look at the \"Using apply in pandas\" notebook \n",
    "- *TIP: It's probably worth it to print the fields first, then save them to a CSV once you know it's all working.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4104757-violations.csv successfully saved\n",
      "0801306-violations.csv successfully saved\n",
      "3609931-violations.csv successfully saved\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_violations_csv(row):\n",
    "    url='https://arlweb.msha.gov/drs/drshome.htm'\n",
    "    violations_MineID = row['id']\n",
    "    driver.get(url)\n",
    "    \n",
    "    mineID_Field = driver.find_element_by_name(\"MineId\")\n",
    "    xPath_SearchButton = '//*[@id=\"content\"]/table[3]/tbody/tr[3]/td[2]/input'\n",
    "    searchButton = driver.find_element_by_xpath(xPath_SearchButton)\n",
    "    mineID_Field.click()\n",
    "    mineID_Field.send_keys(violations_MineID)\n",
    "    searchButton.click()\n",
    "    \n",
    "    beginningDate_field = driver.find_element_by_name(\"BDate\")\n",
    "    violations_button = driver.find_element_by_xpath(\"//input[(@type='radio') and (@value = 'Violations*')]\")\n",
    "    submit_button = driver.find_element_by_xpath(\"//input[(@alt='Submit Request')]\")\n",
    "    \n",
    "    beginningDate_field.send_keys(\"1/1/1995\")\n",
    "    violations_button.click()\n",
    "    submit_button.click()\n",
    "    \n",
    "    doc = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "    violations_list = []\n",
    "    violations = []\n",
    "    violations = doc.find_all(\"tr\",attrs={'class':'drsviols'})\n",
    "    if violations:\n",
    "        for violation in violations:\n",
    "            data = []\n",
    "            data = violation.find_all(\"td\")\n",
    "            if data:\n",
    "                current = {}\n",
    "                current[\"Citation number\"] = data[2].text.strip()\n",
    "                \n",
    "                #exception handling first -- not all columns filled\n",
    "                if len(data)<13:\n",
    "                    current[\"Proposed penalty\"] = \"\"\n",
    "                    current[\"Amount paid to date\"] = \"\"\n",
    "                        \n",
    "                    #exception 1 \"Not assessed yet\"\n",
    "                    if len(data[10].find_all('font'))>2:\n",
    "                        current[\"Case number\"] = \"\"\n",
    "                        current[\"Standard violated\"] = data[10].find_all('font')[2].text.strip()\n",
    "                        current[\"Link to standard\"] = data[10].find('a')['href']\n",
    "                        \n",
    "                    #exception 2 \"Non-assessable\"\n",
    "                    else:\n",
    "                        current[\"Case number\"] = data[3].text.strip()\n",
    "                        current[\"Standard violated\"] = \"\"\n",
    "                        current[\"Link to standard\"] = \"\"\n",
    "                        current[\"Proposed penalty\"] = \"\"\n",
    "                        current[\"Amount paid to date\"] = \"\"\n",
    "                        \n",
    "                else:\n",
    "                    current[\"Case number\"] = data[3].text.strip()\n",
    "                    current[\"Proposed penalty\"] = data[11].text.strip()\n",
    "                    current[\"Amount paid to date\"] = data[14].text.strip()\n",
    "                    current[\"Standard violated\"] = data[10].find_all('font')[2].text.strip()\n",
    "                    current[\"Link to standard\"] = data[10].find('a')['href']\n",
    "\n",
    "                violations_list.append(current)\n",
    "    \n",
    "    #if there's no violation at all   \n",
    "    else:\n",
    "        current = {}\n",
    "        current[\"Citation number\"] = \"\"\n",
    "        current[\"Case number\"] = \"\"\n",
    "        current[\"Proposed penalty\"] = \"\"\n",
    "        current[\"Amount paid to date\"] = \"\"\n",
    "        current[\"Standard violated\"] = \"\"\n",
    "        current[\"Link to standard\"] = \"\"\n",
    "        \n",
    "        violations_list.append(current)\n",
    "\n",
    "    df_violation = pd.DataFrame(violations_list)\n",
    "    filename = violations_MineID+\"-violations.csv\"\n",
    "    df_violation.to_csv(filename, index=False)\n",
    "    print(filename,\"successfully saved\")\n",
    "\n",
    "df_new.apply(save_violations_csv,axis=1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
